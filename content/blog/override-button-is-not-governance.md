---
category: responsible-ai
title: "The Override Button is Not Governance. The Feedback Loop Is."
date: "2026-02-25"
slug: "override-button-is-not-governance"
excerpt: "The EU AI Act requires human-in-loop mechanisms for high-risk AI systems. Most teams will build an override button. That is not governance."
featuredImage: "/images/blog/eu-ai-act-reading.jpg"
---

I spent years working on financial systems where human override was not optional. It was architecture.

One night our end of day trade reconciliation batch started running long. What normally finished in an hour kept going. And going. By the time anyone caught it the process had spilled into the start of business in another geographical region. The backoffice was in chaos.

No AI involved. Just a process running without anyone watching it closely enough to pull the brake in time.

I read the EU AI Act this week. It requires high-risk AI systems to have a human-in-loop mechanism. The ability to manually intervene and supervise operations.

Good start. But here is what most teams will actually build.

An override button. Buried in an admin panel. With no alert telling you when to use it. And when someone does use it the intervention gets logged in a database that nobody reads.

That is not governance. That is a checkbox.

Real governance is when the human intervention means something beyond the moment it happens. When an analyst overrides the AI and that override feeds back into how the system learns next time. When the correction becomes part of the training. When the human is not just a safety valve but an active part of how the system gets better.

My reconciliation batch had an off switch. What it did not have was a way for the person turning it off to teach the system what went wrong.

That is the gap the EU AI Act points toward but does not quite say out loud. And it is the gap that will separate teams genuinely governing their AI from teams who are just compliant on paper.